#+TITLE: Como realizar consultas de maneira simples no ambiente complexo de Big Data com HIVE e Impala

Hive e Impala são frontends que possibilitam um a conexão facilitada aos dados no HDFS.

* Hive
#+BEGIN_QUOTE
The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage.
#+END_QUOTE
Créditos: https://hive.apache.org/

Hive oferece a linguagem HQL (Hive Query Langue), uma abstração de alto nível ao
MapReduce, com linguagem similar ao conhecido SQL.

Geralmente utiliza-se Hive em esteiras de processamento de dados em batch.

#+html: <p align="center"> <figure>
#+html: <img src="figuras/hive_architecture.png" />
#+html: <figcaption>Arquitetura do Hive. Créditos: <a href="https://data-flair.training/blogs/apache-hive-architecture/">dataflair</a> </figcaption>
#+html: </figure> </p>

** Particionamento
Conceito importante. Determina como os dados são armazenados.

Cuidado com os pitfalls:
- Pouco particionamento: não faz bom uso da capacidade de paralelismo dos dados
- Muito particionamento: pode sobrecarregar o namenode, impactando na performance

Ver [[https://blog.cloudera.com/improving-query-performance-using-partitioning-in-apache-hive/][Improving Query Performance Using Partitioning in Apache Hive]].

* Impala
#+BEGIN_QUOTE
Apache Impala is the open source, native analytic database
for Apache Hadoop.
#+END_QUOTE
Créditos: https://impala.apache.org/

Assim como o Hive, Impala ambém possui uma linguagem similar a SQL (Impala SQL) para acesso aos dados no HDFS.

A diferença é que o Impala não salva os resultados intermediários em disco. Isso
acelera e muito o processamento em comparação com o Hive.

Uma consequência negativa desse fato é que o consumo de memória dessa ferramenta
é muito maior. Isso pode ser um limitante dependendo do tipo de queries
executadas.

Por conta disso, Impala é comumente utilizado em pipelines de dados real-time.

* Prática
** Hive
- Utilitários
#+BEGIN_SRC sql
set hive.cli.print.header=true;
set hive.cli.print.current.db=true;
#+END_SRC

- Criar tabela em cima de pasta do HDFS.
#+BEGIN_SRC sql
CREATE EXTERNAL TABLE TB_EXT_EMPLOYEE(
id STRING,
groups STRING,
age STRING,
active_lifestyle STRING,
salary STRING)
ROW FORMAT DELIMITED FIELDS
TERMINATED BY '\;'
STORED AS TEXTFILE
LOCATION '/user/hive/warehouse/external/tabelas/employee'
tblproperties ("skip.header.line.count"="1");
#+END_SRC

- Enviar dados para a LOCATION especificada pela tabela acima.
#+BEGIN_SRC sql
hdfs dfs -put /home/everis/employee.txt /user/hive/warehouse/external/tabelas/employee
#+END_SRC

- Melhorar tabela acima com os tipos apropriados.
#+BEGIN_SRC sql
CREATE TABLE TB_EMPLOYEE(
id INT,
groups STRING,
age INT,
active_lifestyle STRING,
salary DOUBLE)
PARTITIONED BY (dt_processamento STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '|'
STORED AS PARQUET TBLPROPERTIES ("parquet.compression"="SNAPPY");

insert into table TB_EMPLOYEE partition (dt_processamento='20201118')
select
id,
groups,
age,
active_lifestyle,
salary
from TB_EXT_EMPLOYEE;
#+END_SRC

- Criar tabela em cima de pasta no HDFS (segundo exemplo)
#+BEGIN_SRC sql
create external table localidade(
street string,
city string,
zip string,
state string,
beds string,
baths string,
sq_ft string,
type string,
sale_date string,
price string,
latitude string,
longitude string)
PARTITIONED BY (particao STRING)
ROW FORMAT DELIMITED FIELDS TERMINATED BY ","
STORED AS TEXTFILE
location '/user/hive/warehouse/external/tabelas/localidade'
tblproperties ("skip.header.line.count"="1");
#+END_SRC

- Alternativamente, criar tabela com base em arquivo. Hive envia dados para o HDFS automaticamente.
#+BEGIN_SRC sql
load data local inpath '/home/everis/base_localidade.csv'
into table teste.localidade partition (particao='2021-01-21');
#+END_SRC

*** Join
- Sintaxe
#+BEGIN_SRC sql
join_table:
    table_reference [INNER] JOIN table_factor [join_condition]
  | table_reference {LEFT|RIGHT|FULL} [OUTER] JOIN table_reference join_condition
  | table_reference LEFT SEMI JOIN table_reference join_condition
  | table_reference CROSS JOIN table_reference [join_condition] (as of Hive 0.10)

table_reference:
    table_factor
  | join_table

table_factor:
    tbl_name [alias]
  | table_subquery alias
  | ( table_references )

join_condition:
    ON expression
#+END_SRC

- Join tradicional
#+BEGIN_SRC sql
SELECT a.* FROM a JOIN b ON (a.id = b.id)
#+END_SRC

- Join implicito
#+BEGIN_SRC sql
SELECT *
FROM table1 t1, table2 t2, table3 t3
WHERE t1.id = t2.id AND t2.id = t3.id AND t1.zipcode = '02535';
#+END_SRC

*** Detalhes HQL
CREATE EXTERNAL vs MANAGED TABLE

- External - Quando a tablea é apagada, os dados permanecem
- Managed - Apaga os dados quando a tabela é deletada

** Dia-a-dia
O uso do Hive/Impala no cotidiano de um engenheiro de dados é exemplificado a seguir.

Em geral, essas ferramentas são utilizadas diretamente através da linha de comando ou então em scripts que orquestram consultas complexas.

#+BEGIN_SRC sql
LOAD DATA LOCAL INPATH '${hiveconf:path_file}' INTO TABLE ${hiveconf:table} PARTITION(dt_processamento='${hiveconf:dt_processamento}');
#+END_SRC

#+BEGIN_SRC shell
#!/bin/bash

dt_processamento=$(date '+%Y-%m-%d')
path_file='/home/cloudera/hive/datasets/employee.txt'
table=beca.ext_p_employee
load=/home/cloudera/hive/load.hql

hive -hiveconf dt_processamento=${dt_processamento} -hiveconf table=${table} -hiveconf path_file=${path_file} -f $load 2>> log.txt

hive_status=$?

if [ ${hive_status} -eq 0 ];
then
        echo -e "\nScript executado com sucesso"
else
        echo -e "\nHouve um erro na ingestao do arquivo "

impala-shell -q 'INVALIDATE METADATA beca.ext_p_employee;'

fi
#+END_SRC

* Recursos
[[https://drive.google.com/file/d/1duwf7g9lfAsIOJWRL26tx8RBfV8ySPon/view?usp=sharing][Slides da aula]]

[[https://gitlab.com/vmb1/hive][Repositório da aula]]

[[https://data-flair.training/blogs/apache-hive-architecture/][Hive Architecture]]

[[https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Joins][Hive Language Manual - Joins]]

[[https://blog.cloudera.com/improving-query-performance-using-partitioning-in-apache-hive/][Improving Query Performance Using Partitioning in Apache Hive]]

[[https://impala.apache.org/][Apache Impala]]

* Voltar
[[https://github.com/atgmello/engenharia-dados-aceleracao#engenharia-de-dados][Sumário]]
